title: "Server mesh 架构"
date: Mar 23, 2018
draft: false
author: "Andrew Jenkins"
summary: "这是介绍服务网格的软件架构方面系列文章的第二篇。"
tags: ["server mesh","microservice"]
categories: ["server mesh","microservice"]

服务网格架构

原文地址：https://blog.aspenmesh.io/blog/2018/03/service-mesh-architectures/

*注意：这是介绍服务网格的软件架构方面系列文章的第二篇。要了解更多，请查看[*The Path to Service Mesh.*](https://blog.aspenmesh.io/blog/2018/03/the-path-to-service-mesh/)。*

如果你正在围绕微服务构建软件和团队，并且正在寻找更快、更灵活地迭代的方法。服务网格可以帮助您在保持（或增强）可见性和控制的同时做到这一点。这篇博文中，我将讨论一个服务网格究竟是什么，以及在选择和部署一个网格时可能需要考虑的因素。

那么，什么是服务网格？它与你现有的架构有什么不同？服务网格是一个通信层，它运行在请求/响应的上层，为健康的微服务解锁某些模式。我最喜欢的几点：

- 不承担可信周边的零信任安全。
- 跟踪显示一个微服务与另一个微服务如何通讯，及为什么通讯。
- 故障注入和容错，可以让您通过实验验证应用的弹性。
- 实现复杂的路由，可以让你做到如A/B测试，快速版本控制和部署，并且对请求是透明的。

# 为什么是新的时期？

看了上面那个列表，你可能会想“如果没有Service Mesh，我一样可以做到这一切”，你是对的。 相同的逻辑适用于滑动窗口协议或请求框架。 但是，一旦出现了符合您需求的新兴标准，那么依靠该标准而不是自己实现它会更有效。 Service Mesh是微服务模式的新的层面。

服务网络仍处于初期阶段，尚未出现成文标准，但有足够的经验表明一些最佳实践已开始变得清晰。 随着前沿领导者尝试开发自己的实践方法，通过比较笔记并提炼最佳实践通常是很有用的方法。 我们已经看到Kubernetes成为生产环境中运行Web应用程序容器的标准方法。 我最喜欢的标准是紧急的但不是强迫的：对于通用API，协议和概念达成一致意见既不太早也不太晚是一门艺术。

想想计算机网络的历史。在分组交换网络的创新之后，我们发现我们中的许多人正在创建虚拟路由 - 使用握手，重传和互连网将一堆数据包转换为有序的字节流。出于互操作性和简单性的考虑，出现了“最佳实践”流数据包：TCP（RFC675的引入很好地解释了在这层上的内容）。当日还有其他选择 - 我在空间网络中使用了Licklider传输协议，其中分布式拥塞控制既不必要也不高效。您的浏览器可能已在使用QUIC。然而，对TCP的标准化使得一代程序员摆脱了滑动窗口，重试和拥塞崩溃的实现（除了实现它的那些包头之外）。

接下来，我们发现许多请求/响应协议在TCP之上运行。其中许多最终迁移到HTTP（或HTTP / 2或gRPC等续集）。如果您可以将通信分解为“方法，元数据，正文”，那么您应该查看类似HTTP的协议来管理成帧，从正文中分离元数据以及解决行头阻塞问题。这不仅仅是浏览器应用程序 - 像Mongo这样的数据库提供HTTP接口，因为无处不在的HTTP解锁了大量的工具和开发人员知识。

您可以将服务网格视为微服务而生的下一层通信模式的词典，API和实现。

好的，这层该处在哪里？你有几个选择：

- 用库的形式在您的微服务应用程序导入和使用。
- 用节点代理或守护程序的形式为特定节点/计算机上的所有容器提供服务。
- 用Sidecar的形式与应用程序一起运行在容器中。

# 库

软件中库的方法是原创的。它简单明了。在这种架构中，每个微服务应用程序包中都有实现服务网格功能的库。像Hystrix和Ribbon这样的库就是用的这种方法。

这适用于运行它们的团队专门用一种语言编写的应用程序（这样可以很容易地插入库）。库方法也不需要与底层基础架构进行太多合作 - 容器调度器（如Kubernetes）不需要关心您运行的是Hystrix增强型应用程序。

关于多语言库有一些工作（重新实现相同的逻辑）。这里的挑战是一遍又一遍地复制同样的事所涉及的复杂性和精力的投入。

我们看到在我们的用户群中对库模型的采用非常有限，因为我们的大多数用户正在运行用许多不同语言编写的应用程序（多语言），并且还运行一些不是由他们自己编写的应用程序，因此注入库是不可行的。

这种模型在工作审计方面具有优势：微服务执行相关的代码是在微服务内运行的。信任边界也很小 - 您只需要信任在自己进程中调用的库，而不一定是调用在网络的某个地方的远程服务。该代码具有和库所在的微服务一样多的特权。代码的执行也是在微服务的环境中执行的，因此很容易公平地分配CPU时间片或内存等资源 - 操作系统可能会去完成。

![picture](https://ws1.sinaimg.cn/large/006XVfd7gy1ft2yu15ollj30fx0an3z0.jpg)

# 节点代理

节点代理模型是下一个替代方案。在此体系结构中，每个节点上都运行一个单独的代理（通常是用户进程），为异构的工作负载提供服务。比较下，该模型与库模型相反：它不关心应用程序的语言，但可以为许多不同的微服务租户提供服务。

Linkerd在Kubernetes的推荐部署就是这样的。与F5的应用服务代理（ASP）和Kubernetes默认的kube-proxy一样。

由于每个节点上都需要一个节点代理，因此需要与基础架构进行一些协作 - 如果没有一点协作，此模型就无法工作。通过类比，大多数应用程序不能只选择自己的TCP堆栈，猜一个短暂的端口号，直接发送或接收TCP数据包 - 他们将其委托给基础设施（操作系统）。



![agent](https://ws1.sinaimg.cn/large/006XVfd7gy1ft2yu1ipj2j30gd0b2t9d.jpg)

这个模型强调工作资源共享，而不是工作审计 - 如果节点代理分配一些内存来缓冲我的微服务的数据，它可能会在几秒钟内转向并使用该缓冲区为您的服务提供数据。这可能非常有效，但有滥用的途径。如果我的微服务请求所有缓冲区空间，节点代理需要确保它首先在缓冲区空间为微服务提供一个快照。您需要更多代码来管理每个共享资源。

从共享中受益的另一个工作资源是配置信息。将一个配置副本分发到每个节点比将每个节点上的一个配置副本分发到每个节点要便宜。

容器化微服务依赖的许多功能由节点代理或在拓扑上等效的东西提供。想想kubelet初始化你的pod，你最喜欢的CNI守护进程如flanneld，或者稍微伸展你的大脑，甚至操作系统内核本身就像节点代理模型一样。



# 边车

边车是社区的新生儿。这是Istio与Envoy使用的模型。 Conduit还使用了边车方法。在边车部署中，您为每个应用程序容器部署了一个相邻的容器。对于服务网格，边车接管进出应用程序容器的所有网络流量。

我到目前为止讨论的许多取舍，这种方法介于库和节点代理模型之间。例如，您可以部署sidecar服务网格，而无需在每个节点上运行新代理（因此您不需要基础结构的协作就可以部署该代理），但是您将运行相同边车的多个副本。另外一个角度看：我可以为一组微服务安装一个服务网格，你也可以安装一个不同的服务网格（有一些特定告警的实现）我们不需要沟通协调。这在服务网格的早期是非常强大的，我们可能会共享同一个Kubernetes集群但用途不同，会使用不同的功能集，或者可兼容前沿技术的尝试和可靠可信技术实现。


边车有利于工作审计，特别是在一些与安全相关的方面。例如：假设我使用服务网格来提供零信任模式的安全性。我希望服务网格以加密方式验证连接的两端（客户端和服务器）。我们首先考虑使用节点代理：当我的pod想成为另一个服务器pod的客户端时，节点代理将代表我的pod进行身份验证。节点代理也在服务其他pod，因此必须确保另一个pod不能代表我的pod进行身份验证去欺骗他。如果我们考虑边车的情况，我pod的边车不会服务于其他pod。我们可以遵循最小特权原则，并在认证密钥，内存和网络功能方面满足这个pod最低限度的需求。

![sidecar](https://ws1.sinaimg.cn/large/006XVfd7gy1ft2yu1chcrj30gf0awdgg.jpg)

因此，从外部看，边车与其附属的应用程序具有相同的权限。另一方面，边车需要介入应用程序和外部服务之间。这会产生一些安全顾虑：你即希望边车拥有尽可能少的权限，但你又需要给它足够的权限来控制进出应用程序的流量。例如，在Istio中，负责设置sidecar的init容器当前具有NET_ADMIN权限（用于设置必要的iptables规则）。使用初始化是较好的安全实践 - 它用最少的数量的权限然后消失，但NET_ADMIN的所有内容都代表了被攻击的点。 （好消息 - 聪明的人们正在努力进一步加强这一点）。

一旦边车连接到应用程序，从安全角度来看，它们非常接近。但没有您在函数中调用（如库）那么近，通常比调用多租户的节点代理更接近。在Kubernetes中使用Istio时，您的应用容器通过与pod中共享的网络命名空间内的loopback接口与边车通讯 - 因此其他pod和节点代理通常无法看到该通信。

大多数Kubernetes集群每个节点有多个pod（因此每个节点有多个sidecar）。如果每个sidecar都需要知道“整个配置”（无论这在你环境中意味着什么），那么你将需要更多的带宽来分配该配置（以及更多的内存来存储它的副本）。因此，你不得不给每个边车的配置范围加以限制，这是很强的 - 但同样存在相反的力量：某些东西（在Istio的情况下，Pilot）必须花费更多精力为每个边车减少配置。

另一方面是通过边车复制其他东西会产生相似的开销。好消息是容器运行时将重用容器镜像之类的东西，当它们完全相同并且您正在使用正确的驱动程序时，磁盘损失并不重要，并且代码块也会在内存中共享。但是每个边车的特定内存对于那辆边车来说都是独一无二的，所以控制它是很重要的，并且避免通过在每个边车上做一堆复制工作来使你的边车“重量级”。

依靠边车的服务网格在功能完整性和轻量级之间找到了良好的平衡。


# 节点代理或边车模型会占上风吗？
我想你可能会看到两者都存在。现在看来似乎是边车服务网格的最佳的：新生技术，快速迭代和逐步替换。随着服务网格的成熟和变化的的降低，我们将看到更多节点代理模型的应用。

随着服务网格实现的成熟和集群变得越来越大，节点代理模型的优势会更重要：

- 通过节点共享开销（尤其是内存）
- 更少、更容易扩展和分发配置信息
- 精心构建的节点代理可以有效地把服务一个应用程序的资源转移给另一个应用

Sidecar是一种向应用程序提供服务（如高级通信代理和服务网格）的方法。它特别适用于容器和Kubernetes。它的一些最大优势包括：

- 可以在没有中央协调的情况下逐步的添加到现有群集
- 为应用程序执行的工作将统计到该应用程序
- App-to-sidecar通信比app-to-agent更容易保护

# 下一步是什么？
正如Shawn在他的帖子中谈到的那样，我们一直在考虑微服务如何在几年内改变网络基础设施的要求。Istio的支持和增长向我们证明，有一个社区准备开发和制定规范，并且会有一个良好的架构与其一起实现。

Istio正在推进最先进的微服务通信，我们很高兴能使该技术更易于操作，可靠且适合您的团队在私有云，公共云或混合中的工作。